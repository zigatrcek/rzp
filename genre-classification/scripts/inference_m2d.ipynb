{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M2D Electronic Music Genre Inference\n",
    "\n",
    "This notebook loads a trained M2D genre classifier and performs inference on new audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziga/miniconda3/envs/dl/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from portable_m2d import PortableM2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " using 151 parameters, while dropped 9 out of 160 parameters from m2d_vit_base-80x1001p16x16-221006-mr7_as_46ab246d/weights_ep69it3124-0.47929.pth\n",
      " (dropped: ['module.ar.runtime.to_spec.mel_basis', 'module.ar.runtime.to_spec.stft.wsin', 'module.ar.runtime.to_spec.stft.wcos', 'module.ar.runtime.to_spec.stft.window_mask', 'module.head.norm.running_mean'] ...)\n",
      "<All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PortableM2D(\n",
       "  (backbone): LocalViT(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): Identity()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): Identity()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (to_spec): MelSpectrogram(\n",
       "    Mel filter banks size = (80, 201), trainable_mel=False\n",
       "    (stft): STFT(n_fft=400, Fourier Kernel size=(201, 1, 400), iSTFT=False, trainable=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load M2D base model\n",
    "model = PortableM2D(\n",
    "    weight_file='m2d_vit_base-80x1001p16x16-221006-mr7_as_46ab246d/weights_ep69it3124-0.47929.pth',\n",
    "    num_classes=None\n",
    ")\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained classifier\n",
    "checkpoint = torch.load('best_genre_classifier.pth')\n",
    "num_classes = 5  # Set this to match your number of genres\n",
    "classifier = nn.Linear(3840, num_classes).to(device)\n",
    "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "classifier.eval()\n",
    "\n",
    "# Map indices to genre names\n",
    "idx_to_genre = {0: 'ambient', 1: 'drum_and_bass', 2: 'house', 3: 'techno', 4: 'trance'}  # Adjust these to match your genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_genre(audio_path):\n",
    "    \"\"\"Predict genre for a single audio file\"\"\"\n",
    "    # Load audio\n",
    "    waveform, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if sr != model.cfg.sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr, model.cfg.sample_rate)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    # Convert to mono if stereo\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "    \n",
    "    # Move to device\n",
    "    waveform = waveform.to(device)\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(waveform.unsqueeze(0))  # Add batch dimension\n",
    "        embeddings = embeddings.mean(dim=1)  # Average over time\n",
    "        \n",
    "        # Get predictions\n",
    "        outputs = classifier(embeddings)\n",
    "        probs = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        pred = outputs.argmax(dim=1)\n",
    "    \n",
    "    # Get genre name and probability\n",
    "    genre = idx_to_genre[pred.item()]\n",
    "    confidence = probs[0, pred].item()\n",
    "    \n",
    "    # Get all probabilities\n",
    "    all_probs = {idx_to_genre[i]: probs[0, i].item() for i in range(num_classes)}\n",
    "    \n",
    "    return {\n",
    "        'predicted_genre': genre,\n",
    "        'confidence': confidence,\n",
    "        'all_probabilities': all_probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_directory(directory):\n",
    "    \"\"\"Predict genres for all audio files in a directory\"\"\"\n",
    "    directory = Path(directory)\n",
    "    results = []\n",
    "\n",
    "    \n",
    "    # Get all audio files in all subdirectories\n",
    "    audio_files = list(directory.glob('**/*.wav')) + list(directory.glob('**/*.mp3'))\n",
    "\n",
    "    \n",
    "    for audio_file in tqdm(audio_files, desc='Predicting genres'):\n",
    "        try:\n",
    "            prediction = predict_genre(audio_file)\n",
    "            results.append({\n",
    "                'file': str(audio_file),\n",
    "                **prediction\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {audio_file}: {e}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted genre: techno (confidence: 100.00%)\n",
      "\n",
      "All probabilities:\n",
      "ambient: 0.00%\n",
      "drum_and_bass: 0.00%\n",
      "house: 0.00%\n",
      "techno: 100.00%\n",
      "trance: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Example usage for a single file\n",
    "result = predict_genre(\"/mnt/g/glasba/minimal/02. Floating Points - Birth4000.mp3\")\n",
    "print(f\"Predicted genre: {result['predicted_genre']} (confidence: {result['confidence']:.2%})\")\n",
    "print(\"\\nAll probabilities:\")\n",
    "for genre, prob in result['all_probabilities'].items():\n",
    "    print(f\"{genre}: {prob:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18822c1fc5bf4b65992e2d0b3d2cdea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting genres:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[src/libmpg123/id3.c:process_comment():584] error: No comment text / valid description?\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>predicted_genre</th>\n",
       "      <th>confidence</th>\n",
       "      <th>all_probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/010. cajmere, daja...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.999964</td>\n",
       "      <td>{'ambient': 1.9782055767775253e-12, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/08-eric_prydz-woz_...</td>\n",
       "      <td>techno</td>\n",
       "      <td>0.998484</td>\n",
       "      <td>{'ambient': 2.4735991033253413e-10, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/11. Todd Terry - S...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.964874</td>\n",
       "      <td>{'ambient': 6.005754471516411e-07, 'drum_and_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/2 Feeling For You ...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.988789</td>\n",
       "      <td>{'ambient': 8.604713053195212e-10, 'drum_and_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/20. Benny Benassi,...</td>\n",
       "      <td>techno</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>{'ambient': 3.225889404234218e-15, 'drum_and_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/305. Shakedown - A...</td>\n",
       "      <td>techno</td>\n",
       "      <td>0.701145</td>\n",
       "      <td>{'ambient': 1.1366687755962057e-12, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/A-Trak - Bubble Gu...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.601523</td>\n",
       "      <td>{'ambient': 2.1735168331815657e-07, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/barbara tucker - b...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>{'ambient': 7.305317684114243e-09, 'drum_and_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/Cajmere - Brighter...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>{'ambient': 6.222221089063895e-12, 'drum_and_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/Cassius - Feeling ...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.992378</td>\n",
       "      <td>{'ambient': 1.2867519272319328e-09, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/Disco Kandi 2 - 10...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>{'ambient': 1.9203243162291272e-10, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/Dusty Springfield ...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>{'ambient': 1.1854554671231199e-08, 'drum_and_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>/mnt/g/glasba/hiša/classics/Michael Gray - The...</td>\n",
       "      <td>house</td>\n",
       "      <td>0.773557</td>\n",
       "      <td>{'ambient': 2.6816316528455175e-11, 'drum_and_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 file predicted_genre  \\\n",
       "0   /mnt/g/glasba/hiša/classics/010. cajmere, daja...           house   \n",
       "1   /mnt/g/glasba/hiša/classics/08-eric_prydz-woz_...          techno   \n",
       "2   /mnt/g/glasba/hiša/classics/11. Todd Terry - S...           house   \n",
       "3   /mnt/g/glasba/hiša/classics/2 Feeling For You ...           house   \n",
       "4   /mnt/g/glasba/hiša/classics/20. Benny Benassi,...          techno   \n",
       "5   /mnt/g/glasba/hiša/classics/305. Shakedown - A...          techno   \n",
       "6   /mnt/g/glasba/hiša/classics/A-Trak - Bubble Gu...           house   \n",
       "7   /mnt/g/glasba/hiša/classics/barbara tucker - b...           house   \n",
       "8   /mnt/g/glasba/hiša/classics/Cajmere - Brighter...           house   \n",
       "9   /mnt/g/glasba/hiša/classics/Cassius - Feeling ...           house   \n",
       "10  /mnt/g/glasba/hiša/classics/Disco Kandi 2 - 10...           house   \n",
       "11  /mnt/g/glasba/hiša/classics/Dusty Springfield ...           house   \n",
       "12  /mnt/g/glasba/hiša/classics/Michael Gray - The...           house   \n",
       "\n",
       "    confidence                                  all_probabilities  \n",
       "0     0.999964  {'ambient': 1.9782055767775253e-12, 'drum_and_...  \n",
       "1     0.998484  {'ambient': 2.4735991033253413e-10, 'drum_and_...  \n",
       "2     0.964874  {'ambient': 6.005754471516411e-07, 'drum_and_b...  \n",
       "3     0.988789  {'ambient': 8.604713053195212e-10, 'drum_and_b...  \n",
       "4     0.999986  {'ambient': 3.225889404234218e-15, 'drum_and_b...  \n",
       "5     0.701145  {'ambient': 1.1366687755962057e-12, 'drum_and_...  \n",
       "6     0.601523  {'ambient': 2.1735168331815657e-07, 'drum_and_...  \n",
       "7     0.999607  {'ambient': 7.305317684114243e-09, 'drum_and_b...  \n",
       "8     0.999987  {'ambient': 6.222221089063895e-12, 'drum_and_b...  \n",
       "9     0.992378  {'ambient': 1.2867519272319328e-09, 'drum_and_...  \n",
       "10    0.999988  {'ambient': 1.9203243162291272e-10, 'drum_and_...  \n",
       "11    0.999637  {'ambient': 1.1854554671231199e-08, 'drum_and_...  \n",
       "12    0.773557  {'ambient': 2.6816316528455175e-11, 'drum_and_...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example usage for a directory\n",
    "results = predict_directory(\"/mnt/g/glasba/hiša/classics\")\n",
    "\n",
    "# Display results as a table\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
